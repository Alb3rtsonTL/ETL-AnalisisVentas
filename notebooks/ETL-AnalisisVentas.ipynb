{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 📊Sistema de Análisis de Ventas con Proceso ETL\n",
        "\n",
        "Este notebook implementa un **proceso ETL completo** para consolidar datos de clientes, productos y ventas desde múltiples fuentes y cargarlos en MySQL para análisis.\n",
        "\n",
        "<h4>Diagramas:</h4>\n",
        "<div>\n",
        "    <img alt=\"Imagen del Diagrama ER\" src=\"../docs/DiagramaER.png\" style=\"float: left;\"/>\n",
        "    <img alt=\"Imagen del flujo ETL\" src=\"../docs/DiagramaFlujoETL.png\" style=\"*float: right;\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports y Conexión\n",
        "import pandas as pd\n",
        "import mysql.connector\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Datos de conexión\n",
        "DB_USER = \"root\"\n",
        "DB_PASS = \"\"\n",
        "DB_HOST = \"localhost\"\n",
        "DB_NAME = \"sales_db\"\n",
        "\n",
        "engine = create_engine(f\"mysql+mysqlconnector://{DB_USER}:{DB_PASS}@{DB_HOST}/{DB_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Carga de Datos\n",
        "\n",
        "Cargo los CSV desde la carpeta `data/`:\n",
        "\n",
        "- `customers.csv` Información de clientes\n",
        "- `products.csv` Información de productos\n",
        "- `orders.csv` Información de pedidos/ventas\n",
        "- `order_details.csv` Detalles de pedidos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar CSVs\n",
        "customers = pd.read_csv(\"../data/customers.csv\")\n",
        "products = pd.read_csv(\"../data/products.csv\")\n",
        "orders = pd.read_csv(\"../data/orders.csv\")\n",
        "order_details = pd.read_csv(\"../data/order_details.csv\")\n",
        "\n",
        "print(customers.head())\n",
        "print(products.head())\n",
        "print(orders.head())\n",
        "print(order_details.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Limpieza y Normalización\n",
        "\n",
        "- Elimino los duplicados, aplicando algo de normalización\n",
        "- Relleno valores nulos básicos en los registros\n",
        "- Aseguro que los tipos de datos sean correctos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Limpiar y Normalizar\n",
        "\n",
        "# Quitar duplicados\n",
        "customers.drop_duplicates(inplace=True)\n",
        "products.drop_duplicates(inplace=True)\n",
        "orders.drop_duplicates(inplace=True)\n",
        "order_details.drop_duplicates(inplace=True)\n",
        "\n",
        "# Rellenar nulos básicos\n",
        "customers.fillna({\"Email\":\"\", \"Phone\":\"\"}, inplace=True)\n",
        "products.fillna({\"Category\":\"Unknown\"}, inplace=True)\n",
        "\n",
        "# Asegurar tipos\n",
        "customers[\"CustomerID\"] = customers[\"CustomerID\"].astype(int)\n",
        "products[\"ProductID\"] = products[\"ProductID\"].astype(int)\n",
        "orders[\"OrderID\"] = orders[\"OrderID\"].astype(int)\n",
        "orders[\"CustomerID\"] = orders[\"CustomerID\"].astype(int)\n",
        "orders[\"OrderDate\"] = pd.to_datetime(orders[\"OrderDate\"], errors=\"coerce\")\n",
        "order_details[\"OrderID\"] = order_details[\"OrderID\"].astype(int)\n",
        "order_details[\"ProductID\"] = order_details[\"ProductID\"].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Carga Inicial a MySQL\n",
        "\n",
        "- Limpio las tablas existentes\n",
        "- Procedo a insertar clientes, productos y pedidos en la base de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar en MySQL\n",
        "with engine.begin() as conn:\n",
        "    # Limpiar tablas antes de insertar\n",
        "    conn.exec_driver_sql(\"DELETE FROM order_details\")\n",
        "    conn.exec_driver_sql(\"DELETE FROM orders\")\n",
        "    conn.exec_driver_sql(\"DELETE FROM products\")\n",
        "    conn.exec_driver_sql(\"DELETE FROM customers\")\n",
        "\n",
        "customers.to_sql(\"customers\", engine, if_exists=\"append\", index=False)\n",
        "products.to_sql(\"products\", engine, if_exists=\"append\", index=False)\n",
        "orders.to_sql(\"orders\", engine, if_exists=\"append\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Manejo de Duplicados en Detalles de Pedido\n",
        "\n",
        "- Detecto y busco duplicados por `OrderID` y `ProductID`\n",
        "- Para despues agrupar y sumar `Quantity` y `TotalPrice`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manejar duplicados en order_details sumando cantidades y precios\n",
        "dups = order_details[order_details.duplicated(subset=[\"OrderID\",\"ProductID\"], keep=False)]\n",
        "print(dups.head())\n",
        "print(\"Duplicados encontrados:\", len(dups))\n",
        "\n",
        "order_details = order_details.drop_duplicates(subset=[\"OrderID\",\"ProductID\"])\n",
        "\n",
        "# Agrupar duplicados sumando Quantity y TotalPrice\n",
        "order_details = (\n",
        "    order_details\n",
        "    .groupby([\"OrderID\",\"ProductID\"], as_index=False)\n",
        "    .agg({\"Quantity\":\"sum\",\"TotalPrice\":\"sum\"})\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Carga Optimizada de Order Details\n",
        "\n",
        "- Aqui debido a que son mas de 60 mil registros voy a usar una inserción por bloques (`chunksize`) y multi-insert (`method='multi'`) para que el MySQL pueda recibir los datos en paquetes de 10 mil registros evitando que el servidor se atasque y controlando un poco el rendimiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar order_details con optimizaciones chunksize y multi-insert\n",
        "order_details.to_sql(\n",
        "    \"order_details\",\n",
        "    engine,\n",
        "    if_exists=\"append\",\n",
        "    index=False,\n",
        "    chunksize=10000,   # inserta de 10000 en 10000\n",
        "    method=\"multi\"    # agrupa filas en un solo INSERT\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Validación de Datos Cargados\n",
        "\n",
        "- Estas consultas rápidas van a confirmar la cantidad de registros en cada tabla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validación\n",
        "with engine.connect() as conn:\n",
        "    print(pd.read_sql(\"SELECT COUNT(*) AS total_customers FROM customers\", conn))\n",
        "    print(pd.read_sql(\"SELECT COUNT(*) AS total_products FROM products\", conn))\n",
        "    print(pd.read_sql(\"SELECT COUNT(*) AS total_orders FROM orders\", conn))\n",
        "    print(pd.read_sql(\"SELECT COUNT(*) AS total_order_details FROM order_details\", conn))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
